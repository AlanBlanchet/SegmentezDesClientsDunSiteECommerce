{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simulation\n",
        "\n",
        "Dans cette partie j'ai un peu reporté les concepts de la partie \"essai\" car j'étais un peu triste au début de ne pas avoir eu d'assez beaux clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "import umap\n",
        "from src.view import view_clusters, view_projection\n",
        "import numpy as np\n",
        "import squarify\n",
        "import math\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import DistanceMetric\n",
        "from scipy import stats\n",
        "from src.dataset import get_data_until\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed = Path(\"data/processed\")\n",
        "\n",
        "customers = pd.read_csv(processed / \"unique_customer_orders2.csv\")\n",
        "customers.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On va déjà plotter la RFM pour voir s'il y a une différence par rapport à avant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RFM = [\"recency\", \"amount\", \"number_of_orders\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[RFM][\"recency\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_rfm = customers[RFM]\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(x=customers_rfm[RFM[0]], y=customers_rfm[RFM[1]], z=customers_rfm[RFM[2]], opacity=0.3, color=customers[\"wealthy\"])\n",
        "fig.update_layout(\n",
        "    width=1400,\n",
        "    height=800,\n",
        "    scene={f\"{a}axis\": {\"title\":{\"text\":f\"{t} ({a})\"}} for a,t in zip([\"x\",\"y\",\"z\"], RFM)}\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut donc essayer de rajouter des features au fur et à mesure parmis celles extraites\n",
        "\n",
        "On va commencer par scaler et encoder nos données si besoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "customers[\"frequent_cat\"] = encoder.fit_transform(customers[\"frequent_cat\"])\n",
        "customers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[[\"amount\"]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[[\"recency\"]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title(\"Pairplot for some features and RFM\")\n",
        "sns.pairplot(customers[RFM + [\"respected_ratio\", \"estimation_error\", \"freight_value\", \"review_score\"]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut maintenant refaire notre clusering avec les nouvelles features pour voir si elles aides à identifier des clusters.\n",
        "\n",
        "Plus tard on s'occupera de regarder les outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = [\"delivery_delay\", \"estimation_error\", \"number_of_orders\", \"respected_ratio\", \"lat\", \"lng\", \"freight_value\", \"price\", \"review_answer_delay\", \"review_score\", \"review_level\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_scaled = StandardScaler().fit_transform(customers[RFM + cols])\n",
        "X_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models =[\n",
        "    PCA(random_state=0),\n",
        "    KernelPCA(kernel=\"rbf\", random_state=0),\n",
        "    *[TSNE(perplexity=p, n_jobs=-1, random_state=0) for p in np.logspace(-1, 2, num=4)*3]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection(models, X_scaled, hue=customers[\"wealthy\"], p=0.04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection(models, X_scaled, hue=customers[\"frequent_cat\"], p=0.04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_scaled = StandardScaler().fit_transform(customers[RFM + [\"respected_ratio\", \"freight_value\", \"price\", \"review_score\", \"review_level\", \"estimation_error\", \"delivery_delay\", \"number_of_orders\"]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici j'essaye plein de méthodes de façons de projeter mes données pour voir si c'est concluant d'où l'utilisation de ma fonction view_projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection(models, X_scaled, hue=customers[\"wealthy\"], p=0.04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection([*[umap.UMAP(n_neighbors=n, random_state=0) for n in range(2,20, 4)]], X_scaled, hue=customers[\"wealthy\"], p=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection([TSNE(n_iter=2000, perplexity=30, random_state=0), TSNE(n_iter=2000, perplexity=300, random_state=0)], X_scaled, hue=customers[\"wealthy\"], p=0.05)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je stock donc mes meilleurs projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "favorite_projectors = [\n",
        "    TSNE(n_iter=1200, perplexity=30, random_state=0, n_jobs=-1),\n",
        "    umap.UMAP(n_neighbors=16, random_state=0, n_jobs=-1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for projector in favorite_projectors:\n",
        "    y = projector.fit_transform(X_scaled[:5000])\n",
        "\n",
        "    visualizer = SilhouetteVisualizer(KMeans(n_init=\"auto\"), k=(4,20), timings=False)\n",
        "    visualizer.fit(y)\n",
        "    visualizer.poof()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for projector in favorite_projectors:\n",
        "    print(type(projector).__name__)\n",
        "\n",
        "    y = projector.fit_transform(X_scaled[:1000])\n",
        "\n",
        "    plt.figure()\n",
        "    visualizer = KElbowVisualizer(KMeans(n_init=\"auto\", random_state=0), k=(4,20), timings=False)\n",
        "    visualizer.fit(y)\n",
        "    visualizer.show()\n",
        "\n",
        "    k = visualizer.elbow_value_\n",
        "\n",
        "    model = KMeans(n_clusters=k, random_state=0)\n",
        "    labels = model.fit_predict(y)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    sns.scatterplot(x=y.T[0], y=y.T[1], hue=labels, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for projector in favorite_projectors:\n",
        "    print(type(projector).__name__)\n",
        "\n",
        "    y = projector.fit_transform(X_scaled)\n",
        "\n",
        "    plt.figure()\n",
        "    visualizer = KElbowVisualizer(KMeans(n_init=\"auto\", random_state=0), k=(4,20), timings=False, n_jobs=-1)\n",
        "    visualizer.fit(y)\n",
        "    visualizer.show()\n",
        "\n",
        "    k = visualizer.elbow_value_\n",
        "\n",
        "    model = KMeans(n_clusters=k, random_state=0)\n",
        "    labels = model.fit_predict(y)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    sns.scatterplot(x=y.T[0], y=y.T[1], hue=labels, ax=ax)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je vais donc revenir aux bases et faire cela avec le moins de features possible pour rester dans un point de vue métier.\n",
        "\n",
        "Ici on peut très bien critiquer mon travail en disant qu'il y a trop de features qui brouillent les clients intéressant des non intéressants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Voici les colonnes que j'ai choisis\n",
        "cols = RFM\n",
        "X = customers[cols]\n",
        "X_scaled = StandardScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for projector in favorite_projectors:\n",
        "    print(type(projector).__name__)\n",
        "\n",
        "    y = projector.fit_transform(X_scaled)\n",
        "\n",
        "    plt.figure()\n",
        "    visualizer = KElbowVisualizer(KMeans(n_init=\"auto\", random_state=0), k=(2,14), timings=False, n_jobs=-1)\n",
        "    visualizer.fit(y)\n",
        "    visualizer.show()\n",
        "\n",
        "    k = visualizer.elbow_value_\n",
        "\n",
        "    model = KMeans(n_clusters=k, random_state=0)\n",
        "    labels = model.fit_predict(y)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    sns.scatterplot(x=y.T[0], y=y.T[1], hue=labels, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = umap.UMAP(n_neighbors=3, n_components=3, random_state=0, n_jobs=-1).fit_transform(X_scaled)\n",
        "\n",
        "px.scatter_3d(x=y.T[0], y=y.T[1], z=y.T[2], opacity=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KElbowVisualizer(KMeans(random_state=0))\n",
        "model.fit(X_scaled)\n",
        "model.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KMeans(n_clusters=4, n_init=\"auto\")\n",
        "model.fit(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.scatter_3d(x=X_scaled.T[0], y=X_scaled.T[1], z=X_scaled.T[2], color=model.labels_, opacity=0.3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Itération 2\n",
        "\n",
        "J'ai l'impression que certaines analyses ne servent à rien. Je vais essayer d'utiliser une méthode RFM que j'ai vu sur Kaggle qui consiste à créer à partir des données une pré-segmentation pour savoir si on doit oui ou non être préocupper par un client ce qui nous permet de connaître et différencier les bons des mauvais clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers = pd.read_csv(processed / \"unique_customer_orders3.csv\")\n",
        "customers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[\"segment\"].describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut donc refaire les clustering intéressants mais en coloriant par la segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[\"segment\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = customers[\"segment\"].value_counts()\n",
        "norm = count / count.sum()\n",
        "labels = pd.Series(count.index).str.cat(\" ( \" + (norm * 100).round(2).astype(str).values + \"% )\")\n",
        "squarify.plot(count, label=labels, color = ['gold', 'teal', 'steelblue', 'limegreen', 'darkorange', 'coral'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_scaled = StandardScaler().fit_transform(customers[RFM])\n",
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "view_projection(favorite_projectors, X_scaled, hue=customers[\"segment\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque que les clients fidèles sont bien éparpillés dans les clusters"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est déjà pas mal. Voici le résultat d'une étude du meilleur K avec KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KMeans(random_state=0, n_init=\"auto\")\n",
        "\n",
        "visualizer = KElbowVisualizer(model, k=range(2,14), timings=False)\n",
        "visualizer.fit(X_scaled)\n",
        "visualizer.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cols in [[\"frequency\"],\n",
        "             [\"frequency\", \"freight_value\"],\n",
        "             [\"frequency\", \"review_level\", \"review_score\"],\n",
        "             [\"delivery_delay\"],\n",
        "             [\"frequency\", \"review_level\", \"review_score\", \"freight_value\", \"delivery_delay\", \"respected_ratio\"]]:\n",
        "    X_scaled = StandardScaler().fit_transform(customers[RFM + cols])\n",
        "    view_projection(favorite_projectors, X_scaled, hue=customers[\"segment\"])\n",
        "\n",
        "    plt.figure()\n",
        "    model = KMeans(random_state=0, n_init=\"auto\")\n",
        "    visualizer = KElbowVisualizer(model, k=range(2,10), timings=False)\n",
        "    visualizer.fit(X_scaled)\n",
        "    visualizer.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# colonnes sélectionnées\n",
        "data = customers\n",
        "\n",
        "cols = [\"recency\", \"amount\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(data[cols])\n",
        "\n",
        "model = KMeans(n_init=\"auto\", n_clusters=4, random_state=0)\n",
        "model.fit(X_scaled)\n",
        "\n",
        "customers_true_labels = model.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for m in tqdm(range(1,25)):\n",
        "    # On perd des clients qu'on avait auparavant\n",
        "    data_m = get_data_until(month=m)\n",
        "\n",
        "    # Les clients correspondant dans 'customers'\n",
        "    customers_m = customers[customers.customer_unique_id.isin(data_m.customer_unique_id)]\n",
        "    customers_labels = customers_true_labels[customers_m.index]\n",
        "\n",
        "    # On transform avec le même scaler\n",
        "    X_scaled = scaler.transform(data_m[cols])\n",
        "\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    # On récupère le score ARI\n",
        "    scores.append(adjusted_rand_score(customers_labels, model.labels_))\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title(\"ARI scores per month difference\")\n",
        "plt.plot(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for d in tqdm(range(30, 90, 7)):\n",
        "    # On perd des clients qu'on avait auparavant\n",
        "    data_m = get_data_until(days=d)\n",
        "\n",
        "    # Les clients correspondant dans 'customers'\n",
        "    customers_m = customers[customers.customer_unique_id.isin(data_m.customer_unique_id)]\n",
        "    customers_labels = customers_true_labels[customers_m.index]\n",
        "\n",
        "    # On transform avec le même scaler\n",
        "    X_scaled = scaler.transform(data_m[cols])\n",
        "\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    # On récupère le score ARI\n",
        "    scores.append((d, adjusted_rand_score(customers_labels, model.labels_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (d, score) in scores:\n",
        "    print(f\"{d=} ; {score=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(scores)\n",
        "days = X[:, 0]\n",
        "scores_d = X[:, 1]\n",
        "\n",
        "plt.title(\"ARI scores per day difference\")\n",
        "plt.plot(days, scores_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for d in tqdm(range(50, 65, 1)):\n",
        "    # On perd des clients qu'on avait auparavant\n",
        "    data_m = get_data_until(days=d)\n",
        "\n",
        "    # Les clients correspondant dans 'customers'\n",
        "    customers_m = customers[customers.customer_unique_id.isin(data_m.customer_unique_id)]\n",
        "    customers_labels = customers_true_labels[customers_m.index]\n",
        "\n",
        "    # On transform avec le même scaler\n",
        "    X_scaled = scaler.transform(data_m[cols])\n",
        "\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    # On récupère le score ARI\n",
        "    scores.append((d, adjusted_rand_score(customers_labels, model.labels_)))\n",
        "\n",
        "X = np.array(scores)\n",
        "days = X[:, 0]\n",
        "scores_d = X[:, 1]\n",
        "\n",
        "plt.title(\"ARI scores per day difference\")\n",
        "plt.plot(days, scores_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RM = [\"recency\", \"amount\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X2 = get_data_until(days=56)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1 = customers[customers.customer_unique_id.isin(X2.customer_unique_id)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(X1.customer_unique_id == X2.customer_unique_id).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1[RM].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X2[RM].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = ['recency', 'delivery_delay', 'estimation_error',\n",
        "       'number_of_orders', 'respected_ratio', 'amount', 'lat', 'lng',\n",
        "       'frequency', 'freight_value', 'review_answer_delay',\n",
        "       'review_score', 'review_level']\n",
        "\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = customers[cols].corr()\n",
        "\n",
        "sns.heatmap(corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_dists(df):\n",
        "    import math\n",
        "    l = math.ceil(len(df.columns) / 3)\n",
        "\n",
        "    fig, axs = plt.subplots(l, 3, figsize=(20,l*5))\n",
        "\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for ax, col in zip(axs, df.columns):\n",
        "        sns.histplot(df[col], ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_dists(customers[[\"recency\", \"delivery_delay\", \"estimation_error\", \"respected_ratio\", \"number_of_orders\", \"amount\", \"frequency\", \"freight_value\", \"review_answer_delay\", \"review_score\", \"review_level\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_cols = [\"delivery_delay\", \"amount\", \"freight_value\", \"review_answer_delay\", \"number_of_orders\"]\n",
        "\n",
        "customers[[x + \"_log\" for x in log_cols]] = customers[log_cols].apply(lambda x: x+1e-8).apply(np.log)\n",
        "customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_dists(customers[np.array(list(zip(log_cols, [x + \"_log\" for x in log_cols]))).flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers[[x + \"_log\" for x in log_cols]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_cols = cols + [x + \"_log\" for x in log_cols]\n",
        "std_cols = [x + \"_std\" for x in all_cols]\n",
        " \n",
        "customers[std_cols] = scaler.fit_transform(customers[all_cols])\n",
        "customers.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "all_cols = all_cols + std_cols\n",
        "\n",
        "mm_cols = [x + \"_mm\" for x in all_cols]\n",
        "\n",
        "customers[mm_cols] = MinMaxScaler().fit_transform(customers[all_cols])\n",
        "customers.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_cols = ['amount_log_std_mm', 'number_of_orders_log_std_mm', 'recency_std_mm', 'respected_ratio_std_mm', 'freight_value_log_std_mm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset = customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "viz = KElbowVisualizer(KMeans(random_state=0, n_init=\"auto\"), k=(2,12), timings=False)\n",
        "viz.fit(subset[use_cols])\n",
        "viz.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#projector = TSNE(n_components=2, n_jobs=-1, random_state=0, perplexity=120, learning_rate=100)\n",
        "\n",
        "dists = [\"euclidean\", \"chebyshev\", \"correlation\", \"hellinger\"]\n",
        "\n",
        "for neighbor in tqdm([5, 10, 20, 30, 40, 50]):\n",
        "    fig, axs = plt.subplots(math.ceil(len(dists) / 2), 1 if len(dists) == 1 else 2, figsize=(20,20))\n",
        "    axs = axs.flatten()\n",
        "    for ax, dist in tqdm(zip(axs, dists)):\n",
        "        ax.set_title(dist)\n",
        "        projector = umap.UMAP(n_neighbors=neighbor, random_state=0, n_jobs=-1, repulsion_strength=1.2, metric=dist)\n",
        "        projector.fit(subset[use_cols])\n",
        "        y = projector.embedding_.T\n",
        "        sns.scatterplot(x=y[0], y=y[1], hue=subset[\"segment\"], ax=ax)\n",
        "    plt.show(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected = ['amount_log_std_mm', 'number_of_orders_log_std_mm', 'recency_std_mm', 'respected_ratio_std_mm', 'freight_value_log_std_mm']\n",
        "\n",
        "projector = umap.UMAP(n_neighbors=50, random_state=0, n_jobs=-1, repulsion_strength=1.2)\n",
        "\n",
        "model = KMeans(random_state=0, n_init=\"auto\", n_clusters=3)\n",
        "model.fit(customers[selected])\n",
        "\n",
        "projector.fit(customers[selected])\n",
        "\n",
        "y = projector.embedding_.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2, figsize=(20,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "sns.scatterplot(x=y[0], y=y[1], hue=customers[\"segment\"], ax=axs[0])\n",
        "sns.scatterplot(x=y[0], y=y[1], hue=model.labels_, ax=axs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "viz = KElbowVisualizer(KMeans(random_state=0, n_init=\"auto\"), k=(2,12), timings=False)\n",
        "viz.fit(y.T)\n",
        "viz.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DBSCAN(n_jobs=-1)\n",
        "model.fit(y.T)\n",
        "sns.scatterplot(x=y[0], y=y[1], hue=model.labels_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modèle fixe et maintenance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SpectralClustering(n_clusters=4, n_jobs=-1)\n",
        "y_pred = y[:,:500]\n",
        "print(y_pred.shape)\n",
        "model.fit(y_pred.T)\n",
        "sns.scatterplot(x=y_pred[0], y=y_pred[1], hue=model.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist = DistanceMetric.get_metric('euclidean')\n",
        "knn = NearestNeighbors(n_neighbors=model.n_neighbors, metric='precomputed')\n",
        "knn.fit(model.affinity_matrix_)\n",
        "\n",
        "distances, indices = knn.kneighbors(dist.pairwise([[1,1]], y_pred.T))\n",
        "\n",
        "sns.scatterplot(x=y_pred[0], y=y_pred[1], hue=model.labels_)\n",
        "sns.scatterplot(x=[1], y=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist = DistanceMetric.get_metric('euclidean')\n",
        "knn = NearestNeighbors(n_neighbors=model.n_neighbors, metric='precomputed')\n",
        "knn.fit(model.affinity_matrix_)\n",
        "\n",
        "distances, indices = knn.kneighbors(dist.pairwise(y.T, y_pred.T))\n",
        "\n",
        "labels = stats.mode(model.labels_[indices], axis=1)[0].flatten()\n",
        "\n",
        "sns.scatterplot(x=y[0], y=y[1], hue=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colonnes dont on a besoin. Pour rappel nos colonnes scalées sont :\n",
        "# ['amount_log_std_mm', 'number_of_orders_log_std_mm', 'recency_std_mm', 'respected_ratio_std_mm', 'freight_value_log_std_mm']\n",
        "log_selected = [\"amount\", \"number_of_orders\", \"freight_value\"]\n",
        "# On selectionne toutes les données pour le standard scaler et le minmax\n",
        "selected = [\"amount\", \"number_of_orders\", \"recency\", \"respected_ratio\", \"freight_value\"]\n",
        "\n",
        "# On conserve les données dont on a besoin uniquement\n",
        "df = customers[selected].copy()\n",
        "\n",
        "# On scale les données\n",
        "# LOG\n",
        "def log_scale(x):\n",
        "    return np.log(x+1e-8)\n",
        "df[log_selected] = df[log_selected].apply(log_scale)\n",
        "\n",
        "# STD (selected == df.columns)\n",
        "std = StandardScaler()\n",
        "df[selected] = std.fit_transform(df)\n",
        "\n",
        "# MM\n",
        "mm = MinMaxScaler()\n",
        "df[selected] = mm.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(X):\n",
        "    X[log_selected] = log_scale(X[log_selected])\n",
        "    X[selected] = std.transform(X)\n",
        "    X[selected] = mm.transform(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[selected].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Projection\n",
        "projector = umap.UMAP(n_neighbors=50, random_state=0, n_jobs=-1, repulsion_strength=1.2)\n",
        "projector.fit(df)\n",
        "y = projector.embedding_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.scatterplot(x=y.T[0], y=y.T[1], hue=customers[\"segment\"]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pour l'ARI on doit recalculer à chaque fois le SpectralClustering et notre calcul de neighbor (évidemment sinon c'est de la triche !)\n",
        "def model_f(X, n_spectral=None, verbose=True):\n",
        "    if(n_spectral is None):\n",
        "        n_spectral = int(X.shape[0] * 0.008)\n",
        "        if verbose: print(f\"Using {n_spectral=}\")\n",
        "    # Random pick des n_spectral\n",
        "    ids = np.random.choice(X.shape[0], n_spectral, replace=False)\n",
        "    X_spectral = X[ids]\n",
        "\n",
        "    # SC\n",
        "    if verbose: print(\"Fitting SpectralClustering\")\n",
        "    model = SpectralClustering(n_clusters=4, n_jobs=-1)\n",
        "    model.fit(X_spectral)\n",
        "\n",
        "    # NN\n",
        "    if verbose: print(\"Calculating NearestNeibors from samples\")\n",
        "    dist = DistanceMetric.get_metric('euclidean')\n",
        "    knn = NearestNeighbors(n_neighbors=3, metric='precomputed')\n",
        "    knn.fit(model.affinity_matrix_)\n",
        "\n",
        "    # Calcul de distance moins lourd - récupération des indexes des neighbors\n",
        "    indices = knn.kneighbors(dist.pairwise(X, X_spectral))[1]\n",
        "\n",
        "    # Labels\n",
        "    if verbose: print(\"Getting labels\")\n",
        "    labels = stats.mode(model.labels_[indices], axis=1, keepdims=False)[0].flatten()\n",
        "    if verbose: \n",
        "        sns.scatterplot(x=X.T[0], y=X.T[1], hue=labels)\n",
        "        plt.show()\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_true_labels = model_f(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "tqdm_b = tqdm(range(40, 20*30, 10))\n",
        "for d in tqdm_b:\n",
        "    try:\n",
        "        # On perd des clients qu'on avait auparavant\n",
        "        data_m = get_data_until(days=d)\n",
        "\n",
        "        # Les clients correspondant dans 'df'\n",
        "        df_m = df[customers.customer_unique_id.isin(data_m.customer_unique_id)]\n",
        "        df_labels = df_true_labels[df_m.index]\n",
        "\n",
        "        # Preprocess\n",
        "        data_m = preprocess(data_m[selected].copy())\n",
        "        \n",
        "        emb = projector.transform(data_m)\n",
        "\n",
        "        labels = model_f(emb, verbose=False)\n",
        "\n",
        "        # On récupère le score ARI\n",
        "        ari = adjusted_rand_score(df_labels, labels)\n",
        "        tqdm_b.set_postfix({\"score\": ari})\n",
        "        scores.append(ari)\n",
        "    except Exception as e:\n",
        "        print(f\"Error at {d=}\", e)\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "plt.title(\"ARI score per day difference\")\n",
        "ax.yaxis.set_ticks(np.arange(-2, 2, 0.25))\n",
        "plt.plot(range(40, 20*30, 10), scores)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
